{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2    \n",
    "# import numpy as np\n",
    "\n",
    "# def picSuccessful(self_color):\n",
    "\n",
    "#         area_coordinates = (300, 100, 100, 100)   #x,y,heigth,width\n",
    "        \n",
    "#         # Show the original image with the contour\n",
    "#         image = cv2.imread(\"orange.png\")\n",
    "#         #image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # Extract the region of interest based on the provided coordinates\n",
    "#         x, y, width, height = area_coordinates\n",
    "#         roi = image[y:y+height, x:x+width]\n",
    "        \n",
    "#         # Convert the region of interest to the HSV color space\n",
    "#         hsv_roi = cv2.cvtColor(roi, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "#         # Define color ranges for red, orange, yellow, and green\n",
    "#         color_ranges = {\n",
    "#             'red': ([0, 50, 50], [10, 255, 255]),\n",
    "#             'orange': ([11, 50, 50], [25, 255, 255]),\n",
    "#             'yellow': ([26, 50, 50], [34, 255, 255]),\n",
    "#             'green': ([35, 50, 50], [70, 255, 255])\n",
    "#         }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # farbe = (0, 255, 0)  # Green color (BGR format)\n",
    "#         # thickness = 2  # Thickness of the rectangle border\n",
    "#         # cv2.rectangle(image, (x, y), (x+width, y+height), farbe, thickness)\n",
    "\n",
    "#         # # Display the image with the rectangle\n",
    "#         # cv2.imshow('Image with Rectangle', image)\n",
    "\n",
    "#         # # Create a window to display the image\n",
    "#         # cv2.namedWindow('Image with Rectangle', cv2.WINDOW_NORMAL)\n",
    "#         # cv2.imshow('Image with Rectangle', image)\n",
    "#         # cv2.waitKey(0)\n",
    "#         # cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#         # Check if the expected color is present in the region of interest\n",
    "#         if self_color in color_ranges:\n",
    "#             lower, upper = color_ranges[self_color]\n",
    "#             lower = np.array(lower, dtype=np.uint8)\n",
    "#             upper = np.array(upper, dtype=np.uint8)\n",
    "#             mask = cv2.inRange(hsv_roi, lower, upper)\n",
    "#             if cv2.countNonZero(mask) > 0:\n",
    "#                 return True\n",
    "            \n",
    "#         return False\n",
    "\n",
    "\n",
    "\n",
    "        # if self.color == \"red\":\n",
    "        #     color_index = 2\n",
    "\n",
    "        # if self.color == \"green\":\n",
    "        #     color_index = 0\n",
    "\n",
    "        # if self.color == \"yellow\":\n",
    "        #     color_index = 3\n",
    "\n",
    "        # if self.color == \"orange\":\n",
    "        #     color_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.8.10 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 7982MiB)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 54\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, mask_size)\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m resized_binary_array, mask_size\n\u001b[0;32m---> 54\u001b[0m getYOLOMask()\n",
      "Cell \u001b[0;32mIn[27], line 22\u001b[0m, in \u001b[0;36mgetYOLOMask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m YOLO_IMG_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39morange.png\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# safe the image for YOLO here\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[39m=\u001b[39m YOLO(model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/leon/Documents/Robologics/robologics_brause/src/robogistics_brause/robogistics_brause/object_detection/Yolov8_model/weights/best.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(source\u001b[39m=\u001b[39;49mYOLO_IMG_PATH, save\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_txt\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results: \u001b[39m# only on result in results\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m     \u001b[39m# get array results\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     all_masks \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mmasks\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/yolo/engine/model.py:143\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[0;34m(self, source, stream, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor:\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPredictorClass(overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor\u001b[39m.\u001b[39;49msetup_model(model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m get_cfg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs, overrides)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/yolo/engine/predictor.py:236\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    234\u001b[0m model \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhalf \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m device\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# half precision only supported on CUDA\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoBackend(model, device\u001b[39m=\u001b[39;49mdevice, dnn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdnn, fp16\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhalf)\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[1;32m    238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/nn/autobackend.py:65\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, fuse)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m# NOTE: special case: in-memory pytorch model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m nn_module:\n\u001b[0;32m---> 65\u001b[0m     model \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     66\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfuse() \u001b[39mif\u001b[39;00m fuse \u001b[39melse\u001b[39;00m model\n\u001b[1;32m     67\u001b[0m     names \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mnames \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39mnames  \u001b[39m# get class names\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py:141\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    131\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m    `_apply()` is a function that applies a function to all the tensors in the model that are not\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    parameters or registered buffers\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m        A model that is a Detect() object.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    142\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]  \u001b[39m# Detect()\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, (Detect, Segment)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import pyrealsense2 as rs\n",
    "import tkinter as tk\n",
    "\n",
    "from PIL import ImageTk\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "\n",
    "def getYOLOMask():\n",
    "\n",
    "    YOLO_IMG_PATH = \"orange.png\" # safe the image for YOLO here\n",
    "    model = YOLO(model='/home/leon/Documents/Robologics/robologics_brause/src/robogistics_brause/robogistics_brause/object_detection/Yolov8_model/weights/best.pt')\n",
    "\n",
    "    results = model.predict(source=YOLO_IMG_PATH, save=False, save_txt=False, stream=True)\n",
    "    for result in results: # only on result in results\n",
    "        \n",
    "        # get array results\n",
    "        all_masks = result.masks.data\n",
    "        boxes = result.boxes.data\n",
    "        color = boxes[:, 5] #\n",
    "        idx_masks_color = torch.where(color == 1) # index of the chosen coulour\n",
    "        # use these indices to extract the relevant masks\n",
    "        for index in idx_masks_color:\n",
    "            color_masks = all_masks[index]\n",
    "            result_masks = [[],[]]\n",
    "            for i in range(len(color_masks)):\n",
    "\n",
    "                result_mask = color_masks[i].cpu().numpy()\n",
    "                result_masks[0].append(np.count_nonzero(result_mask))\n",
    "                result_masks[1].append(result_mask)\n",
    "\n",
    "    _, final_mask_list = (list(t) for t in zip(*sorted(zip(result_masks[0], result_masks[1]), reverse=True)))\n",
    "\n",
    "    mask_size = np.count_nonzero(final_mask_list[0])\n",
    "\n",
    "\n",
    "    binary_array = np.where(final_mask_list[0] != 0, 1, 0)\n",
    "    binary_array = binary_array.astype('uint8')\n",
    "    resized_binary_array = cv2.resize(binary_array,(1280, 720))\n",
    "    resized_binary_array.astype('uint8') # nicht sicher ob notwendig\n",
    "\n",
    "    print(\"X\", mask_size)\n",
    "\n",
    "    return resized_binary_array, mask_size\n",
    "\n",
    "getYOLOMask()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
